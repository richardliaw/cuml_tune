# An unique identifier for the head node and workers of this cluster.
cluster_name: gpu-instance-p3

# The maximum number of workers nodes to launch in addition to the head
# node. This takes precedence over min_workers. min_workers default to 0.
min_workers: 0
max_workers: 0

docker:
    image: rapidsai/rapidsai:cuda10.0-runtime-ubuntu18.04
    container_name: ray_docker

provider:
    type: aws
    region: us-east-1
    #    availability_zone: us-west-2a
    # cache_stopped_nodes: True

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu
    ssh_private_key: /Users/rliaw/Research/ec2/clustercfgs/anyscale_cfgs/anyscale.pem
    #ssh_private_key: ~/Research/ec2/clustercfgs/drl.pem

head_node:
    InstanceType: p3.8xlarge
    ImageId: latest_dlami
    KeyName: anyscale
    InstanceMarketOptions:
        MarketType: spot
    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 500

worker_nodes:
    InstanceType: g3.8xlarge
    #ImageId: ami-025ed45832b817a35
    KeyName: anyscale
    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 200


setup_commands:
    #- pip install -U tensorflow-gpu==1.0 mujoco_py
    # - conda uninstall -y wrapt || true
    - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl
    - pip install tabulate
      # - git clone https://github.com/richardliaw/ray; cd ray; git checkout trial_executor_error  &&  python setup-dev.py --yes


file_mounts: {
}

# Custom commands that will be run on the head node after common setup.
head_setup_commands: []

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []
